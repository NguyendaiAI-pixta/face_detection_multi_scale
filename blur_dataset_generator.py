#!/usr/bin/env python3
"""
WiderFace Blur Dataset Generator for Robust Face Detection Training
T·∫°o b·ªô d·ªØ li·ªáu blur v·ªõi ph√¢n c·∫•p ƒë·ªô kh√≥ v√† ch·∫•t l∆∞·ª£ng face ph√π h·ª£p cho training
"""

import cv2
import numpy as np
import os
import json
import random
import shutil
from pathlib import Path
from collections import defaultdict

class WiderFaceBlurDatasetGenerator:
    def create_blur_val(self, wider_val_path, output_base_dir, blur_level='medium'):
        """T·∫°o t·∫≠p val m·ªù t·ª´ t·∫≠p val c·ªßa WiderFace"""
        print(f"\nüîÑ Generating blurred val set from WiderFace val...")
        images_dir = Path(wider_val_path) / "images"
        labels_dir = Path(wider_val_path) / "labels"
        output_img_dir = Path(output_base_dir) / "val" / "images"
        output_lbl_dir = Path(output_base_dir) / "val" / "labels"
        output_img_dir.mkdir(parents=True, exist_ok=True)
        output_lbl_dir.mkdir(parents=True, exist_ok=True)
        # Ch·ªçn blur config
        blur_configs = self.blur_levels.get(blur_level, self.blur_levels['medium'])
        blur_config = random.choice(blur_configs)
        count = 0
        for category_dir in images_dir.iterdir():
            if not category_dir.is_dir():
                continue
            for img_file in category_dir.glob("*.jpg"):
                image = cv2.imread(str(img_file))
                if image is None:
                    continue
                # Apply blur
                blurred_image = self.apply_blur_effects(
                    image, blur_config['type'], blur_config['strength']
                )
                # T·∫°o t√™n file output
                output_name = f"{category_dir.name}_{img_file.stem}_{blur_config['label']}"
                img_output_path = output_img_dir / f"{output_name}.jpg"
                success = cv2.imwrite(str(img_output_path), blurred_image)
                if success:
                    # Copy label file
                    label_file = labels_dir / category_dir.name / f"{img_file.stem}.txt"
                    if label_file.exists():
                        label_output_path = output_lbl_dir / f"{output_name}.txt"
                        shutil.copy2(label_file, label_output_path)
                        count += 1
        print(f"‚úÖ Blurred val set created: {count} images in {output_img_dir}")
    def __init__(self, wider_path):
        """Initialize v·ªõi WiderFace dataset path"""
        self.wider_path = Path(wider_path)
        self.images_dir = self.wider_path / "images"
        self.labels_dir = self.wider_path / "labels"
        
        # Blur configurations t·ª´ nh·∫π ƒë·∫øn n·∫∑ng - ƒëi·ªÅu ch·ªânh h·ª£p l√Ω cho training
        self.blur_levels = {
            'light': [
                {'type': 'gaussian', 'strength': 3, 'label': 'Gaussian_Light'},
                {'type': 'motion', 'strength': 5, 'label': 'Motion_Light'},
                {'type': 'radial', 'strength': 2, 'label': 'Radial_Light'}
            ],
            'medium': [
                {'type': 'gaussian', 'strength': 7, 'label': 'Gaussian_Medium'},
                {'type': 'motion', 'strength': 12, 'label': 'Motion_Medium'},
                {'type': 'radial', 'strength': 4, 'label': 'Radial_Medium'}
            ],
            'heavy': [
                {'type': 'gaussian', 'strength': 12, 'label': 'Gaussian_Heavy'},
                {'type': 'motion', 'strength': 19, 'label': 'Motion_Heavy'},
                {'type': 'radial', 'strength': 6, 'label': 'Radial_Heavy'}
            ]
        }
        
        # WiderFace difficulty categories - ph√¢n lo·∫°i theo ƒë·ªô kh√≥ th·ª±c t·∫ø
        self.easy_categories = [
            "22--Picnic", "20--Family_Group", "50--Celebration_Or_Party",
            "21--Festival", "11--Meeting", "49--Greeting", "19--Couple"
        ]
        
        self.medium_categories = [
            "12--Group", "13--Interview", "29--Students_Schoolkids",
            "7--Cheering", "18--Concerts", "28--Sports_Fan", "23--Shoppers",
            "52--Photographers", "8--Election_Campain"
        ]
        
        self.hard_categories = [
            "3--Riot", "5--Car_Accident", "14--Traffic", "61--Street_Battle",
            "53--Raid", "54--Rescue", "2--Demonstration", "4--Dancing",
            "24--Soldier_Firing", "34--Baseball"
        ]
    
    def load_yolo_labels(self, label_path, img_width, img_height):
        """Load YOLO format labels v√† convert sang pixel coordinates"""
        faces = []
        
        if not label_path.exists():
            return faces
            
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    cls, x_center, y_center, width, height = map(float, parts[:5])
                    
                    # Convert normalized to pixel coordinates
                    x_center_px = x_center * img_width
                    y_center_px = y_center * img_height
                    width_px = width * img_width
                    height_px = height * img_height
                    
                    # Convert to x1, y1, x2, y2
                    x1 = int(x_center_px - width_px / 2)
                    y1 = int(y_center_px - height_px / 2)
                    x2 = int(x_center_px + width_px / 2)
                    y2 = int(y_center_px + height_px / 2)
                    
                    faces.append({
                        'bbox': [x1, y1, x2, y2],
                        'class': int(cls),
                        'confidence': 1.0
                    })
        
        return faces
    
    def get_face_quality_stats(self, label_path, img_width, img_height):
        """Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng faces trong ·∫£nh - ch·ªâ l·∫•y faces >= 32x32"""
        faces = self.load_yolo_labels(label_path, img_width, img_height)
        
        quality_faces = []
        for face in faces:
            x1, y1, x2, y2 = face['bbox']
            width = x2 - x1
            height = y2 - y1
            
            # Ch·ªâ l·∫•y faces c√≥ k√≠ch th∆∞·ªõc >= 32x32 nh∆∞ y√™u c·∫ßu
            if width >= 32 and height >= 32:
                quality_faces.append({
                    'bbox': face['bbox'],
                    'width': width,
                    'height': height,
                    'area': width * height,
                    'size_category': self.classify_face_size(width, height)
                })
        
        return quality_faces
    
    def classify_face_size(self, width, height):
        """Ph√¢n lo·∫°i k√≠ch th∆∞·ªõc face"""
        min_dim = min(width, height)
        if min_dim >= 96:
            return 'large'
        elif min_dim >= 64:
            return 'medium'
        else:  # >= 32
            return 'small'
    
    def sample_images_by_difficulty(self, target_counts):
        """Sample ·∫£nh theo ƒë·ªô kh√≥ v·ªõi t·ª∑ l·ªá 30% easy, 50% medium, 20% hard"""
        sampled_images = {
            'easy': [],
            'medium': [], 
            'hard': []
        }
        
        # Sample easy cases (30%)
        print(f"üîç Sampling easy cases...")
        for category in self.easy_categories:
            cat_dir = self.images_dir / category
            if cat_dir.exists():
                images = list(cat_dir.glob("*.jpg"))
                random.shuffle(images)  # Shuffle ƒë·ªÉ diversity
                sampled = self.filter_quality_images(images, category)
                needed = target_counts['easy'] // len(self.easy_categories)
                sampled_images['easy'].extend(sampled[:needed])
        
        # Sample medium cases (50%)
        print(f"üîç Sampling medium cases...")
        for category in self.medium_categories:
            cat_dir = self.images_dir / category
            if cat_dir.exists():
                images = list(cat_dir.glob("*.jpg"))
                random.shuffle(images)
                sampled = self.filter_quality_images(images, category)
                needed = target_counts['medium'] // len(self.medium_categories)
                sampled_images['medium'].extend(sampled[:needed])
        
        # Sample hard cases (20%)
        print(f"üîç Sampling hard cases...")
        for category in self.hard_categories:
            cat_dir = self.images_dir / category
            if cat_dir.exists():
                images = list(cat_dir.glob("*.jpg"))
                random.shuffle(images)
                sampled = self.filter_quality_images(images, category)
                needed = target_counts['hard'] // len(self.hard_categories)
                sampled_images['hard'].extend(sampled[:needed])
        
        return sampled_images
    
    def filter_quality_images(self, images, category):
        """L·ªçc ·∫£nh c√≥ quality faces >= 32x32"""
        quality_images = []
        
        for img_path in images:
            label_path = self.labels_dir / category / f"{img_path.stem}.txt"
            if not label_path.exists():
                continue
                
            try:
                # Load ·∫£nh ƒë·ªÉ l·∫•y dimensions
                temp_img = cv2.imread(str(img_path))
                if temp_img is None:
                    continue
                    
                h, w = temp_img.shape[:2]
                quality_faces = self.get_face_quality_stats(label_path, w, h)
                
                # Ch·ªâ l·∫•y ·∫£nh c√≥ √≠t nh·∫•t 1 face ch·∫•t l∆∞·ª£ng >= 32x32
                if len(quality_faces) >= 1:
                    quality_images.append({
                        'image_path': img_path,
                        'label_path': label_path,
                        'category': category,
                        'num_quality_faces': len(quality_faces),
                        'quality_faces': quality_faces
                    })
                    
            except Exception as e:
                continue
        
        # Sort theo s·ªë l∆∞·ª£ng quality faces (∆∞u ti√™n ·∫£nh c√≥ nhi·ªÅu faces)
        quality_images.sort(key=lambda x: x['num_quality_faces'], reverse=True)
        return quality_images
    
    def apply_blur_effects(self, image, blur_type='gaussian', strength=5):
        """Apply blur effects v·ªõi parameters ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh h·ª£p l√Ω"""
        if blur_type == 'gaussian':
            # Gaussian blur - kernel size ph·∫£i l·∫ª
            kernel_size = int(strength) * 2 + 1
            return cv2.GaussianBlur(image, (kernel_size, kernel_size), strength/3)
            
        elif blur_type == 'motion':
            # Motion blur - horizontal motion
            kernel_size = int(strength)
            if kernel_size % 2 == 0:
                kernel_size += 1
            kernel_motion_blur = np.zeros((kernel_size, kernel_size))
            kernel_motion_blur[int((kernel_size-1)/2), :] = np.ones(kernel_size)
            kernel_motion_blur = kernel_motion_blur / kernel_size
            return cv2.filter2D(image, -1, kernel_motion_blur)
            
        elif blur_type == 'radial':
            # Radial blur (zoom blur) - t·ª´ center ra ngo√†i
            h, w = image.shape[:2]
            center_x, center_y = w//2, h//2
            
            result = np.zeros_like(image, dtype=np.float64)
            num_layers = max(int(strength), 2)
            
            for i in range(num_layers):
                scale = 1.0 + (i * 0.015)  # Gi·∫£m scale factor ƒë·ªÉ kh√¥ng qu√° m·∫°nh
                M = cv2.getRotationMatrix2D((center_x, center_y), 0, scale)
                layer = cv2.warpAffine(image, M, (w, h))
                result = cv2.addWeighted(result, i/(i+1), layer.astype(np.float64), 1/(i+1), 0)
                
            return np.clip(result, 0, 255).astype(np.uint8)
            
        else:
            # Default gaussian
            return cv2.GaussianBlur(image, (15, 15), strength/5)
    
    def create_blur_dataset(self, total_images=500, output_base_dir="/home/dainguyenvan/project/ARV/auto-footage/yolov7-face/blur_dataset"):
        """T·∫°o b·ªô d·ªØ li·ªáu blur v·ªõi ph√¢n ph·ªëi theo √Ω t∆∞·ªüng c·ªßa b·∫°n"""
        
        # T√≠nh to√°n s·ªë l∆∞·ª£ng theo √Ω t∆∞·ªüng: 30% easy, 50% medium, 20% hard
        target_counts = {
            'easy': int(total_images * 0.3),    # 30%
            'medium': int(total_images * 0.5),  # 50%
            'hard': int(total_images * 0.2)     # 20%
        }
        
        print(f"üéØ Target Distribution (theo √Ω t∆∞·ªüng c·ªßa b·∫°n):")
        print(f"   ‚Ä¢ Easy cases: {target_counts['easy']} images (30%)")
        print(f"   ‚Ä¢ Medium cases: {target_counts['medium']} images (50%)") 
        print(f"   ‚Ä¢ Hard cases: {target_counts['hard']} images (20%)")
        print(f"   ‚Ä¢ Total original: {sum(target_counts.values())} images")
        print(f"   ‚Ä¢ Expected blur variants: ~{sum(target_counts.values()) * 3} (light, medium, heavy)")
        
        # Sample ·∫£nh theo ƒë·ªô kh√≥
        sampled_images = self.sample_images_by_difficulty(target_counts)
        
        # Verify sampling results
        actual_counts = {k: len(v) for k, v in sampled_images.items()}
        print(f"\nüìä Actual Sampled:")
        for difficulty, count in actual_counts.items():
            print(f"   ‚Ä¢ {difficulty.capitalize()}: {count} images")
        
        # T·∫°o output directories
        output_dir = Path(output_base_dir)
        (output_dir / "images").mkdir(parents=True, exist_ok=True)
        (output_dir / "labels").mkdir(parents=True, exist_ok=True)
        
        # Th·ªëng k√™ processing
        stats = defaultdict(int)
        all_results = []
        
        # Process t·ª´ng difficulty level
        for difficulty, images in sampled_images.items():
            if not images:
                continue
                
            print(f"\nüìä Processing {difficulty.upper()} cases: {len(images)} images")
            
            for i, img_data in enumerate(images):
                print(f"   [{i+1:3d}/{len(images)}] {img_data['image_path'].name} (Faces: {img_data['num_quality_faces']})")
                
                # T·∫°o blur variants - ph√¢n b·ªï ƒë·ªÅu light, medium, heavy
                blur_variants = self.generate_blur_variants(
                    img_data, output_dir, difficulty
                )
                
                stats[f'{difficulty}_processed'] += 1
                stats['total_variants'] += len(blur_variants)
                all_results.extend(blur_variants)
        
        # L∆∞u metadata
        metadata = {
            'dataset_info': {
                'creation_date': str(Path().cwd()),
                'source_dataset': 'WiderFace',
                'total_original_images': sum(len(images) for images in sampled_images.values()),
                'total_blur_variants': stats['total_variants'],
                'distribution_target': target_counts,
                'distribution_actual': actual_counts,
                'blur_levels': ['light', 'medium', 'heavy'],
                'blur_types': ['gaussian', 'motion', 'radial'],
                'min_face_size': '32x32 pixels'
            },
            'processing_stats': dict(stats),
            'blur_configurations': self.blur_levels,
            'difficulty_categories': {
                'easy': self.easy_categories,
                'medium': self.medium_categories,
                'hard': self.hard_categories
            },
            'results': all_results
        }
        
        metadata_path = output_dir / "dataset_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"\nüéâ Blur Dataset Generation Completed!")
        print(f"üìä Final Statistics:")
        print(f"   ‚Ä¢ Original images processed: {metadata['dataset_info']['total_original_images']}")
        print(f"   ‚Ä¢ Total blur variants created: {metadata['dataset_info']['total_blur_variants']}")
        print(f"   ‚Ä¢ Average variants per image: {metadata['dataset_info']['total_blur_variants'] / max(1, metadata['dataset_info']['total_original_images']):.1f}")
        print(f"   ‚Ä¢ Output directory: {output_dir}")
        print(f"   ‚Ä¢ Metadata saved: {metadata_path}")
        
        self.print_usage_instructions(output_dir)
        
        return metadata
    
    def generate_blur_variants(self, img_data, output_dir, difficulty):
        """T·∫°o blur variants theo ph√¢n b·ªï ƒë·ªÅu light, medium, heavy"""
        image_path = img_data['image_path']
        label_path = img_data['label_path']
        category = img_data['category']
        
        # Load ·∫£nh g·ªëc
        image = cv2.imread(str(image_path))
        if image is None:
            return []
        
        variants = []
        base_name = f"{difficulty}_{category.replace('--', '_')}_{image_path.stem}"
        
        # T·∫°o blur cho m·ªói level - ph√¢n b·ªï ƒë·ªÅu nh∆∞ y√™u c·∫ßu
        for level_name, level_configs in self.blur_levels.items():
            # Ch·ªçn ng·∫´u nhi√™n 1 blur type t·ª´ level n√†y
            blur_config = random.choice(level_configs)
            
            # Apply blur
            blurred_image = self.apply_blur_effects(
                image, blur_config['type'], blur_config['strength']
            )
            
            # T·∫°o t√™n file output
            output_name = f"{base_name}_{blur_config['label']}"
            
            # Save ·∫£nh
            img_output_path = output_dir / "images" / f"{output_name}.jpg"
            success = cv2.imwrite(str(img_output_path), blurred_image)
            
            if success:
                # Copy label file (gi·ªØ nguy√™n bounding box)
                label_output_path = output_dir / "labels" / f"{output_name}.txt"
                shutil.copy2(label_path, label_output_path)
                
                variants.append({
                    'original_image': str(image_path),
                    'output_image': str(img_output_path),
                    'output_label': str(label_output_path),
                    'difficulty': difficulty,
                    'category': category,
                    'blur_type': blur_config['type'],
                    'blur_strength': blur_config['strength'],
                    'blur_level': level_name,
                    'num_faces': img_data['num_quality_faces']
                })
        
        return variants
    
    def print_usage_instructions(self, output_dir):
        """In h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng dataset cho training"""
        print(f"\nüìñ Usage Instructions:")
        print(f"=" * 50)
        print(f"1. üìÅ Dataset Structure:")
        print(f"   {output_dir}/")
        print(f"   ‚îú‚îÄ‚îÄ images/           # Blur images")
        print(f"   ‚îú‚îÄ‚îÄ labels/           # YOLO format labels") 
        print(f"   ‚îî‚îÄ‚îÄ dataset_metadata.json")
        
        print(f"\n2. üîó Integration v·ªõi Original Dataset:")
        print(f"   ‚Ä¢ Merge v√†o WIDER_train b·∫±ng symlink ho·∫∑c copy")
        print(f"   ‚Ä¢ Update data/widerface.yaml ƒë·ªÉ include blur data")
        print(f"   ‚Ä¢ Ho·∫∑c t·∫°o ri√™ng config cho combined dataset")
        
        print(f"\n3. üöÄ Training Commands:")
        print(f"   # Option 1: Train tr√™n blur data only") 
        print(f"   python train.py --data blur_dataset.yaml")
        print(f"   ")
        print(f"   # Option 2: Combine v·ªõi original data")
        print(f"   python train.py --data combined_widerface.yaml")
        
        print(f"\n4. üìä Expected Benefits:")
        print(f"   ‚Ä¢ Improved robustness trong adverse conditions")
        print(f"   ‚Ä¢ Better generalization cho camera blur")
        print(f"   ‚Ä¢ Enhanced performance trong real-world scenarios")

def main():
    """Main function ƒë·ªÉ ch·∫°y dataset generation"""
    
    print("üöÄ WiderFace Blur Dataset Generator")
    print("=" * 50)
    print("T·∫°o dataset blur cho robust face detection training")
    print("Theo √Ω t∆∞·ªüng: 30% easy, 50% medium, 20% hard cases")
    print("V·ªõi face size >= 32x32, blur levels: light/medium/heavy")
    
    # Configuration
    wider_path = "/home/dainguyenvan/project/ARV/auto-footage/yolov7-face/WIDER_train"
    output_dir = "/mnt/md0/projects/nguyendai-footage/blur_dataset"
    total_images = 600  # S·ªë ·∫£nh g·ªëc ƒë·ªÉ t·∫°o blur variants
    
    # Validate input
    if not Path(wider_path).exists():
        print(f"‚ùå Source dataset not found: {wider_path}")
        return
    
    # Initialize generator
    generator = WiderFaceBlurDatasetGenerator(wider_path)
    
    print(f"\nüìä Configuration:")
    print(f"   ‚Ä¢ Source: {wider_path}")
    print(f"   ‚Ä¢ Output: {output_dir}")
    print(f"   ‚Ä¢ Target images: {total_images}")
    print(f"   ‚Ä¢ Expected variants: ~{total_images * 3}")
    print(f"   ‚Ä¢ Min face size: 32x32 pixels")
    
    print(f"\nüéõÔ∏è  Blur Configurations:")
    for level_name, configs in generator.blur_levels.items():
        print(f"   ‚Ä¢ {level_name.upper()}:")
        for config in configs:
            print(f"     - {config['type'].capitalize()}: strength={config['strength']}")
    
    # Generate dataset
    try:
        print(f"\nüîÑ Starting dataset generation...")
        metadata = generator.create_blur_dataset(
            total_images=total_images,
            output_base_dir=output_dir
        )
        # T·∫°o t·∫≠p val m·ªù t·ª´ WiderFace val
        wider_val_path = "/home/dainguyenvan/project/ARV/auto-footage/yolov7-face/WIDER_val"
        generator.create_blur_val(
            wider_val_path=wider_val_path,
            output_base_dir=output_dir,
            blur_level='medium'  # ho·∫∑c 'light', 'heavy' n·∫øu mu·ªën
        )
        print(f"\n‚úÖ SUCCESS! Blur dataset created successfully")
        print(f"Ready for training v·ªõi robust face detection!")
        return metadata
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
