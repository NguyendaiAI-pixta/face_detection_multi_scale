import os
import sys
import torch
import cv2
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import time
import glob
import json
import re
from typing import List, Tuple, Dict, Any, Optional
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import argparse
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, as_completed
from multiprocessing import Pool, cpu_count

# Set multiprocessing start method to 'spawn' for CUDA compatibility
try:
    multiprocessing.set_start_method('spawn', force=True)
except RuntimeError:
    pass  # Already set

# Import t·ª´ YOLOv7 Face
from models.experimental import attempt_load
from utils.datasets import letterbox
from utils.general import non_max_suppression, scale_coords, check_img_size
from utils.torch_utils import select_device, time_synchronized

# Import t·ª´ MultiScaleFaceDetector
from multi_scale_face_detector import MultiScaleFaceDetector

# Import shared utilities
from utils.preprocess_yolo_predict import (
    normalize_bbox, denormalize_bbox, draw_faces_on_image,
    get_image_paths_from_base, find_images_in_directory,
    load_yolo_model, create_yolo_json_format, save_json_results,
    calculate_face_statistics, print_processing_summary,
    scale_coords_api_approach  # Th√™m coordinate scaling function
)



# Global config
MODEL_PATH = "auto_review_yolo_face_module_weight.pt"  # Model weights
JSON_OUTPUT_DIR = "./api_predict_json_results_df_multi_scale_640_3840_new"
MAX_FACES_IMAGES_DIR = "./api_predict_max_faces_images_640_3840_new"
BASE_IMAGE_PATH = "/mnt/md0/projects/auto_review_footage/"  # ƒê∆∞·ªùng d·∫´n g·ªëc ƒë·∫øn ·∫£nh

# Create output directories
os.makedirs(JSON_OUTPUT_DIR, exist_ok=True)
os.makedirs(MAX_FACES_IMAGES_DIR, exist_ok=True)

# Bi·∫øn global cho c·∫•u h√¨nh multiprocessing
SKIP_PROCESSED = False  # C√≥ b·ªè qua nh·ªØng item ƒë√£ x·ª≠ l√Ω kh√¥ng

# Detection parameters
NUM_GPU = 3  # S·ªë l∆∞·ª£ng GPU th·ª±c t·∫ø (0,1,2)
MAX_ITEMS = 24000  # Gi·ªõi h·∫°n items
CONF_THRES = 0.6  # Confidence threshold
IOU_THRES = 0.3  # NMS threshold
IMG_SIZES = [640, 3840]  # List c√°c k√≠ch th∆∞·ªõc ·∫£nh cho multi-scale detection
NUM_WORKERS = 30  # S·ªë l∆∞·ª£ng worker cho x·ª≠ l√Ω ƒëa lu·ªìng

# CUDA Environment Setup - Let workers handle GPU assignment
# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'  # Commented out - workers will set this
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Use PCI bus order
os.environ['OMP_NUM_THREADS'] = '1'  # Optimize for multi-GPU

# normalize_bbox ƒë√£ ƒë∆∞·ª£c import t·ª´ utils.preprocess_yolo_predict


# draw_faces_on_image v√† get_image_paths_from_base ƒë√£ ƒë∆∞·ª£c import t·ª´ utils.preprocess_yolo_predict


def create_detector(model_path=MODEL_PATH, device='', img_sizes=IMG_SIZES, 
                    conf_thres=CONF_THRES, iou_thres=IOU_THRES):
    """
    T·∫°o m·ªôt MultiScaleFaceDetector v·ªõi GPU selection
    
    Args:
        device: GPU device ('', 'cpu', '0', '1', '2', ho·∫∑c '0,1,2')
    """
    # Initialize CUDA in the new process
    if torch.cuda.is_available():
        torch.cuda.init()
    
    # Since init_worker already set CUDA_VISIBLE_DEVICES, we always use device '0'
    # which will map to the actual GPU assigned to this worker
    device_str = '0' if torch.cuda.is_available() else 'cpu'
    
    current_process = multiprocessing.current_process()
    assigned_gpu = os.environ.get('CUDA_VISIBLE_DEVICES', 'unknown')
    print(f"üîß Creating detector on device: {device_str} (Process: {current_process.name}, Assigned GPU: {assigned_gpu})")
    
    # Ch·ªçn device - always use '0' since CUDA_VISIBLE_DEVICES is set by init_worker
    device_obj = select_device(device_str)
    
    # Kh·ªüi t·∫°o detector
    detector = MultiScaleFaceDetector(
        model_path=model_path,
        device=device_str,
        img_sizes=img_sizes,
        conf_thres=conf_thres,
        iou_thres=iou_thres,
        use_api_preprocess=True
    )
    
    return detector


class MultiScaleFaceDataFramePredictor:
    """
    Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi Multi-scale TTA v√† l∆∞u k·∫øt qu·∫£ v√†o DataFrame
    """
    
    def __init__(self, detector, save_images=True, save_dir='results', base_image_path=None, num_workers=10):
        """
        Kh·ªüi t·∫°o Multi-scale Face DataFrame Predictor
        
        Args:
            detector: MultiScaleFaceDetector ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
            save_images: C√≥ l∆∞u ·∫£nh k·∫øt qu·∫£ hay kh√¥ng
            save_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
            base_image_path: ƒê∆∞·ªùng d·∫´n c∆° s·ªü cho c√°c ·∫£nh (prefix cho relative paths)
            num_workers: S·ªë l∆∞·ª£ng worker cho x·ª≠ l√Ω ƒëa lu·ªìng
        """
        self.detector = detector
        self.save_images = save_images
        self.save_dir = save_dir
        self.base_image_path = base_image_path or ""
        self.num_workers = min(num_workers, multiprocessing.cpu_count())
        
        print(f"üßµ Using {self.num_workers} workers for parallel processing")
        
        # T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ n·∫øu ch∆∞a t·ªìn t·∫°i
        if self.save_images and not os.path.exists(self.save_dir):
            os.makedirs(self.save_dir)
            print(f"‚úÖ Created directory: {self.save_dir}")
    
    def process_image(self, img_path, save_visualization=True):
        """
        X·ª≠ l√Ω m·ªôt ·∫£nh v√† tr·∫£ v·ªÅ th√¥ng tin detections d∆∞·ªõi d·∫°ng DataFrame
        
        Args:
            img_path: ƒê∆∞·ªùng d·∫´n ·∫£nh (relative ho·∫∑c absolute path)
            save_visualization: C√≥ l∆∞u ·∫£nh visualization kh√¥ng
            
        Returns:
            df: DataFrame ch·ª©a th√¥ng tin detections
        """
        # K·∫øt h·ª£p base_image_path n·∫øu img_path kh√¥ng ph·∫£i l√† absolute path
        full_img_path = img_path
        if not os.path.isabs(img_path) and self.base_image_path:
            full_img_path = os.path.join(self.base_image_path, img_path)
            
        # Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng multi-scale detector
        final_detections, img0_shape = self.detector.detect_multi_scale(full_img_path)
        
        # L∆∞u ·∫£nh k·∫øt qu·∫£ n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if self.save_images:
            img_name = os.path.basename(full_img_path)
            output_path = os.path.join(self.save_dir, f"detected_{img_name}")
            self.detector.save_detection_result(full_img_path, final_detections, output_path)
            
            # L∆∞u ·∫£nh visualization n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if save_visualization:
                vis_path = os.path.join(self.save_dir, f"vis_{img_name.split('.')[0]}.png")
                all_scale_detections, _ = self.detector.visualize_multi_scale_results(full_img_path, vis_path)
        
        # T·∫°o DataFrame t·ª´ detections
        if len(final_detections) > 0:
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho DataFrame
            data = []
            for i, det in enumerate(final_detections):
                # Ki·ªÉm tra k√≠ch th∆∞·ªõc c·ªßa det
                if len(det) != 7:
                    # C·ªë g·∫Øng extract th√¥ng tin c·∫ßn thi·∫øt n·∫øu c√≥ th·ªÉ
                    if len(det) >= 5:
                        x1, y1, x2, y2, conf = det[:5]
                        cls = 0 if len(det) <= 5 else det[5]
                        scale_idx = 0 if len(det) <= 6 else det[6]
                    else:
                        continue  # B·ªè qua detection n√†y n·∫øu kh√¥ng ƒë·ªß th√¥ng tin
                else:
                    x1, y1, x2, y2, conf, cls, scale_idx = det
                
                # T√≠nh th√™m c√°c th√¥ng tin h·ªØu √≠ch
                width = x2 - x1
                height = y2 - y1
                area = width * height
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                aspect_ratio = width / height if height > 0 else 0
                
                # X√°c ƒë·ªãnh scale ƒë∆∞·ª£c s·ª≠ d·ª•ng
                if hasattr(self.detector, 'img_sizes') and int(scale_idx) < len(self.detector.img_sizes):
                    scale_used = self.detector.img_sizes[int(scale_idx)]
                else:
                    scale_used = "unknown"
                
                # Th√™m v√†o data
                data.append({
                    'image_path': img_path,
                    'full_image_path': full_img_path,
                    'file_name': os.path.basename(img_path),
                    'face_id': i,
                    'x1': int(x1),
                    'y1': int(y1),
                    'x2': int(x2),
                    'y2': int(y2),
                    'width': int(width),
                    'height': int(height),
                    'area': int(area),
                    'center_x': int(center_x),
                    'center_y': int(center_y),
                    'aspect_ratio': aspect_ratio,
                    'confidence': conf,
                    'scale_used': scale_used
                })
                
            # T·∫°o DataFrame
            df = pd.DataFrame(data)
        else:
            # DataFrame r·ªóng n·∫øu kh√¥ng c√≥ detection
            df = pd.DataFrame(columns=[
                'image_path', 'full_image_path', 'file_name', 'face_id', 
                'x1', 'y1', 'x2', 'y2', 'width', 'height', 'area', 
                'center_x', 'center_y', 'aspect_ratio', 'confidence', 'scale_used'
            ])
        
        return df
    
    def process_directory(self, dir_path, image_formats=None, save_csv=True, save_excel=False):
        """
        X·ª≠ l√Ω t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c v√† tr·∫£ v·ªÅ DataFrame t·ªïng h·ª£p
        
        Args:
            dir_path: ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a ·∫£nh
            image_formats: List c√°c ƒë·ªãnh d·∫°ng ·∫£nh c·∫ßn x·ª≠ l√Ω (None = t·∫•t c·∫£)
            save_csv: C√≥ l∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng CSV kh√¥ng
            save_excel: C√≥ l∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng Excel kh√¥ng
            
        Returns:
            df_all: DataFrame ch·ª©a th√¥ng tin t·∫•t c·∫£ detections
        """
        # M·∫∑c ƒë·ªãnh x·ª≠ l√Ω c√°c ƒë·ªãnh d·∫°ng ·∫£nh ph·ªï bi·∫øn
        if image_formats is None:
            image_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.webp']
        
        # T√¨m t·∫•t c·∫£ file ·∫£nh trong th∆∞ m·ª•c
        image_paths = []
        for ext in image_formats:
            image_paths.extend(glob.glob(os.path.join(dir_path, f"*{ext}")))
            image_paths.extend(glob.glob(os.path.join(dir_path, f"*{ext.upper()}")))
        
        if not image_paths:
            print(f"‚ùå No images found in {dir_path} with formats {image_formats}")
            return pd.DataFrame()
        
        print(f"üîç Found {len(image_paths)} images in {dir_path}")
        
        # X·ª≠ l√Ω t·ª´ng ·∫£nh song song s·ª≠ d·ª•ng multi-threading
        all_dfs = []
        
        # H√†m x·ª≠ l√Ω trong worker thread
        def process_single_image(img_path):
            try:
                df = self.process_image(img_path, save_visualization=False)
                return df
            except Exception as e:
                print(f"‚ùå Error processing {img_path}: {e}")
                return pd.DataFrame()
        
        # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ x·ª≠ l√Ω ƒëa lu·ªìng
        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            # Submit c√°c task
            future_to_path = {executor.submit(process_single_image, img_path): img_path 
                             for img_path in image_paths}
            
            # S·ª≠ d·ª•ng tqdm ƒë·ªÉ hi·ªÉn th·ªã progress bar
            for future in tqdm(as_completed(future_to_path), total=len(image_paths), desc="Processing images"):
                img_path = future_to_path[future]
                try:
                    df = future.result()
                    if not df.empty:
                        all_dfs.append(df)
                except Exception as e:
                    print(f"‚ùå Error retrieving result for {img_path}: {e}")
        
        # K·∫øt h·ª£p t·∫•t c·∫£ DataFrames
        if all_dfs:
            df_all = pd.concat(all_dfs, ignore_index=True)
            
            # L∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng CSV n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if save_csv:
                csv_path = os.path.join(self.save_dir, "face_detections.csv")
                df_all.to_csv(csv_path, index=False)
                print(f"üíæ Saved results to CSV: {csv_path}")
            
            # L∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng Excel n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if save_excel:
                excel_path = os.path.join(self.save_dir, "face_detections.xlsx")
                df_all.to_excel(excel_path, index=False)
                print(f"üíæ Saved results to Excel: {excel_path}")
            
            return df_all
        else:
            print("‚ùå No valid detections found in any image")
            return pd.DataFrame()
    
    def analyze_results(self, df):
        """
        Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ DataFrame
        
        Args:
            df: DataFrame ch·ª©a th√¥ng tin detections
            
        Returns:
            analysis: Dict ch·ª©a c√°c ph√¢n t√≠ch v·ªÅ k·∫øt qu·∫£
        """
        if df.empty:
            return {"error": "No detections to analyze"}
        
        analysis = {}
        
        # T·ªïng s·ªë khu√¥n m·∫∑t ph√°t hi·ªán ƒë∆∞·ª£c
        analysis['total_faces'] = len(df)
        
        # S·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω
        analysis['total_images'] = df['image_path'].nunique()
        
        # S·ªë ·∫£nh c√≥ √≠t nh·∫•t m·ªôt khu√¥n m·∫∑t
        images_with_faces = df.groupby('image_path').size().reset_index(name='face_count')
        analysis['images_with_faces'] = len(images_with_faces)
        
        # S·ªë ·∫£nh kh√¥ng c√≥ khu√¥n m·∫∑t n√†o
        analysis['images_without_faces'] = analysis['total_images'] - analysis['images_with_faces']
        
        # Trung b√¨nh s·ªë khu√¥n m·∫∑t tr√™n m·ªói ·∫£nh
        analysis['avg_faces_per_image'] = analysis['total_faces'] / analysis['total_images']
        
        # Th·ªëng k√™ v·ªÅ k√≠ch th∆∞·ªõc khu√¥n m·∫∑t
        analysis['face_area'] = {
            'min': df['area'].min(),
            'max': df['area'].max(),
            'mean': df['area'].mean(),
            'median': df['area'].median()
        }
        
        # Th·ªëng k√™ v·ªÅ confidence
        analysis['confidence'] = {
            'min': df['confidence'].min(),
            'max': df['confidence'].max(),
            'mean': df['confidence'].mean(),
            'median': df['confidence'].median()
        }
        
        # Ph√¢n b·ªë theo scales
        if 'scale_used' in df.columns:
            scale_counts = df['scale_used'].value_counts().to_dict()
            analysis['scale_distribution'] = scale_counts
        
        return analysis
    
    def generate_report(self, analysis, output_path=None):
        """
        T·∫°o b√°o c√°o t·ª´ k·∫øt qu·∫£ ph√¢n t√≠ch
        
        Args:
            analysis: Dict ch·ª©a c√°c ph√¢n t√≠ch v·ªÅ k·∫øt qu·∫£
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u b√°o c√°o
            
        Returns:
            report_text: N·ªôi dung b√°o c√°o
        """
        if 'error' in analysis:
            return f"Error: {analysis['error']}"
        
        report = []
        report.append("# Face Detection Report")
        report.append(f"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        report.append("## Overall Statistics")
        report.append(f"- Total images processed: {analysis['total_images']}")
        report.append(f"- Total faces detected: {analysis['total_faces']}")
        report.append(f"- Images with at least one face: {analysis['images_with_faces']} ({analysis['images_with_faces']/analysis['total_images']*100:.2f}%)")
        report.append(f"- Images without faces: {analysis['images_without_faces']} ({analysis['images_without_faces']/analysis['total_images']*100:.2f}%)")
        report.append(f"- Average faces per image: {analysis['avg_faces_per_image']:.2f}")
        report.append("")
        
        report.append("## Face Size Statistics")
        report.append(f"- Min area: {analysis['face_area']['min']:.2f} pixels¬≤")
        report.append(f"- Max area: {analysis['face_area']['max']:.2f} pixels¬≤")
        report.append(f"- Mean area: {analysis['face_area']['mean']:.2f} pixels¬≤")
        report.append(f"- Median area: {analysis['face_area']['median']:.2f} pixels¬≤")
        report.append("")
        
        report.append("## Confidence Score Statistics")
        report.append(f"- Min confidence: {analysis['confidence']['min']:.2f}")
        report.append(f"- Max confidence: {analysis['confidence']['max']:.2f}")
        report.append(f"- Mean confidence: {analysis['confidence']['mean']:.2f}")
        report.append(f"- Median confidence: {analysis['confidence']['median']:.2f}")
        report.append("")
        
        if 'scale_distribution' in analysis:
            report.append("## Scale Distribution")
            for scale, count in analysis['scale_distribution'].items():
                report.append(f"- Scale {scale}: {count} faces ({count/analysis['total_faces']*100:.2f}%)")
        
        report_text = "\n".join(report)
        
        # L∆∞u b√°o c√°o n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if output_path:
            with open(output_path, 'w') as f:
                f.write(report_text)
            print(f"üíæ Saved report to: {output_path}")
        
        return report_text


def process_from_csv(csv_path, base_image_path, predictor, output_csv_path=None, output_excel_path=None, save_report=False):
    """
    X·ª≠ l√Ω ·∫£nh t·ª´ CSV c√≥ ch·ª©a ƒë∆∞·ªùng d·∫´n ·∫£nh
    
    Args:
        csv_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV
        base_image_path: ƒê∆∞·ªùng d·∫´n c∆° s·ªü cho ·∫£nh
        predictor: MultiScaleFaceDataFramePredictor ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
        output_csv_path: ƒê∆∞·ªùng d·∫´n l∆∞u k·∫øt qu·∫£ CSV
        output_excel_path: ƒê∆∞·ªùng d·∫´n l∆∞u k·∫øt qu·∫£ Excel
        save_report: C√≥ t·∫°o b√°o c√°o kh√¥ng
    
    Returns:
        df_all: DataFrame ch·ª©a th√¥ng tin t·∫•t c·∫£ detections
    """
    # ƒê·ªçc CSV
    print(f"üìä Reading image paths from CSV: {csv_path}")
    df_input = pd.read_csv(csv_path)
    
    # Ki·ªÉm tra xem CSV c√≥ c·ªôt ƒë∆∞·ªùng d·∫´n ·∫£nh kh√¥ng
    image_path_column = None
    for col in df_input.columns:
        if 'path' in col.lower() or 'image' in col.lower() or 'file' in col.lower():
            image_path_column = col
            break
    
    if not image_path_column:
        print(f"‚ùå No image path column found in CSV. Available columns: {df_input.columns.tolist()}")
        return pd.DataFrame()
    
    # L·∫•y danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh
    image_paths = df_input[image_path_column].tolist()
    print(f"üîç Found {len(image_paths)} image paths in CSV")
    
    # X·ª≠ l√Ω t·ª´ng ·∫£nh song song
    all_dfs = []
    
    # H√†m x·ª≠ l√Ω trong worker thread
    def process_single_image(img_path):
        try:
            df = predictor.process_image(img_path, save_visualization=False)
            return df
        except Exception as e:
            print(f"‚ùå Error processing {img_path}: {e}")
            return pd.DataFrame()
    
    # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ x·ª≠ l√Ω ƒëa lu·ªìng
    with ThreadPoolExecutor(max_workers=predictor.num_workers) as executor:
        # Submit c√°c task
        future_to_path = {executor.submit(process_single_image, img_path): img_path 
                        for img_path in image_paths}
        
        # S·ª≠ d·ª•ng tqdm ƒë·ªÉ hi·ªÉn th·ªã progress bar
        for future in tqdm(as_completed(future_to_path), total=len(image_paths), desc="Processing images from CSV"):
            img_path = future_to_path[future]
            try:
                df = future.result()
                if not df.empty:
                    # Th√™m th√¥ng tin t·ª´ CSV g·ªëc n·∫øu c·∫ßn
                    img_info = df_input[df_input[image_path_column] == img_path].iloc[0].to_dict()
                    for key, value in img_info.items():
                        if key != image_path_column and key not in df.columns:
                            df[key] = value
                    all_dfs.append(df)
            except Exception as e:
                print(f"‚ùå Error retrieving result for {img_path}: {e}")
    
    # K·∫øt h·ª£p t·∫•t c·∫£ DataFrames
    if all_dfs:
        df_all = pd.concat(all_dfs, ignore_index=True)
        
        # L∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng CSV n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if output_csv_path:
            df_all.to_csv(output_csv_path, index=False)
            print(f"üíæ Saved results to CSV: {output_csv_path}")
        
        # L∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng Excel n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if output_excel_path:
            df_all.to_excel(output_excel_path, index=False)
            print(f"üíæ Saved results to Excel: {output_excel_path}")
        
        # Ph√¢n t√≠ch k·∫øt qu·∫£
        if save_report:
            analysis = predictor.analyze_results(df_all)
            report_path = os.path.join(os.path.dirname(output_csv_path or output_excel_path or ''), "detection_report.md")
            predictor.generate_report(analysis, report_path)
        
        return df_all
    else:
        print("‚ùå No valid detections found in any image from CSV")
        return pd.DataFrame()


def detect_faces(detector, img_path):
    """
    Detect faces trong ·∫£nh s·ª≠ d·ª•ng Multi-scale detection
    
    Args:
        detector: MultiScaleFaceDetector ƒë√£ kh·ªüi t·∫°o
        img_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
    
    Returns:
        faces_data: List c√°c face detections [{'bbox': [x1, y1, x2, y2], 'conf': confidence, 'scale_used': scale}]
    """
    try:
        # ƒêo th·ªùi gian
        start_time = time_synchronized()
        
        # Th·ª±c hi·ªán ph√°t hi·ªán khu√¥n m·∫∑t
        final_detections, img0_shape = detector.detect_multi_scale(img_path)
        
        # T√≠nh th·ªùi gian
        elapsed = time_synchronized() - start_time
        
        # Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng k·∫øt qu·∫£
        faces_data = []
        
        for det in final_detections:
            # Ki·ªÉm tra s·ªë l∆∞·ª£ng gi√° tr·ªã trong det
            if len(det) >= 5:
                if len(det) == 7:
                    x1, y1, x2, y2, conf, cls, scale_idx = det
                    scale_idx = int(scale_idx)
                    scale_used = detector.img_sizes[scale_idx] if scale_idx < len(detector.img_sizes) else "unknown"
                else:
                    x1, y1, x2, y2, conf = det[:5]
                    cls = det[5] if len(det) > 5 else 0
                    scale_used = "unknown"
                
                faces_data.append({
                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                    'conf': float(conf),
                    'cls': int(cls),
                    'scale_used': scale_used
                })
        
        return faces_data, elapsed
        
    except Exception as e:
        print(f"L·ªói detect faces cho {img_path}: {e}")
        return [], 0


def init_worker():
    """Initialize worker process with proper CUDA context"""
    import torch
    import os
    import multiprocessing
    
    # Get process ID and assign GPU FIRST - before any CUDA operations
    current_process = multiprocessing.current_process()
    if hasattr(current_process, '_identity') and current_process._identity:
        process_id = current_process._identity[0] - 1
        gpu_id = process_id % NUM_GPU
        # Set CUDA_VISIBLE_DEVICES IMMEDIATELY to restrict GPU visibility
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        print(f"üîß Worker {current_process.name} (PID: {process_id}) assigned to GPU {gpu_id}")
        print(f"    CUDA_VISIBLE_DEVICES set to: {gpu_id}")
    else:
        # Fallback for main process or unexpected cases
        os.environ['CUDA_VISIBLE_DEVICES'] = '0'
        print(f"üîß Worker {current_process.name} using default GPU assignment (GPU 0)")
    
    # Now initialize CUDA after setting the environment
    if torch.cuda.is_available():
        torch.cuda.init()
        # Clear any existing CUDA cache
        torch.cuda.empty_cache()
        print(f"    CUDA initialized, available devices: {torch.cuda.device_count()}")
    else:
        print(f"    CUDA not available in this worker")


def process_item_helper(item_data):
    """
    Wrapper function for process_item that uses global SKIP_PROCESSED parameter
    """
    global SKIP_PROCESSED
    return process_item(item_data, SKIP_PROCESSED)


def process_item(item_data, skip_processed=False):
    """
    X·ª≠ l√Ω m·ªôt item: detect faces cho t·∫•t c·∫£ ·∫£nh v√† t·∫°o JSON output
    
    Args:
        item_data: (item_id, tiny_face_module)
        skip_processed: N·∫øu True, b·ªè qua item ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (c√≥ JSON)
    
    Returns:
        result: (item_id, num_frames, total_faces, total_elapsed)
    """
    item_id, tiny_face_module = item_data
    
    # Ki·ªÉm tra xem k·∫øt qu·∫£ JSON ƒë√£ t·ªìn t·∫°i ch∆∞a
    json_path = os.path.join(JSON_OUTPUT_DIR, f"{item_id}.json")
    max_faces_image_path = os.path.join(MAX_FACES_IMAGES_DIR, f"{item_id}_max_*.jpg")
    max_faces_images = glob.glob(max_faces_image_path)
    
    if skip_processed and os.path.exists(json_path) and max_faces_images:
        # L·∫•y th√¥ng tin c∆° b·∫£n t·ª´ file JSON ƒë√£ t·ªìn t·∫°i
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            # T√¨m shape ƒë·ªÉ x√°c ƒë·ªãnh s·ªë l∆∞·ª£ng frames v√† faces
            for tensor in json_data.get("yolo_face_prediction", []):
                if tensor.get("name") == "yolo-face-bboxes":
                    shape = tensor.get("shape", [0, 0, 0])
                    num_frames = shape[0]
                    max_faces = shape[1]
                    
                    # T√¨m t·ªïng s·ªë faces (lo·∫°i b·ªè c√°c face padding c√≥ bbox [-1,-1,-1,-1])
                    total_faces = 0
                    if "data" in tensor:
                        for frame_data in tensor["data"]:
                            for bbox in frame_data:
                                if bbox[0] > -0.99:  # Kh√¥ng ph·∫£i padding
                                    total_faces += 1
                    
                    # L·∫•y th·ªùi gian x·ª≠ l√Ω t·ª´ JSON n·∫øu c√≥
                    total_elapsed = 0
                    for tensor_time in json_data.get("yolo_face_prediction", []):
                        if tensor_time.get("name") == "yolo-face-total_time":
                            if "data" in tensor_time and tensor_time["data"]:
                                total_elapsed = tensor_time["data"][0]
                    
                    max_faces_count = max([len([b for b in frame if b[0] > -0.99]) for frame in tensor.get("data", [])])
                    print(f"‚úÖ ƒê√£ t·ªìn t·∫°i: Item {item_id}: {num_frames} frames, {total_faces} total faces, max {max_faces_count} faces/frame -> {json_path}")
                    return (item_id, num_frames, total_faces, total_elapsed)
            
            print(f"‚ö†Ô∏è File JSON {json_path} kh√¥ng h·ª£p l·ªá ho·∫∑c thi·∫øu th√¥ng tin, s·∫Ω x·ª≠ l√Ω l·∫°i.")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói ƒë·ªçc file JSON {json_path}: {e}, s·∫Ω x·ª≠ l√Ω l·∫°i.")
    
    try:
        print(f"ƒêang x·ª≠ l√Ω item {item_id} v·ªõi path: {tiny_face_module}")
        
        try:
            # T·∫°o detector v·ªõi GPU auto-selection
            detector = create_detector(device='')  # Auto-select based on process
        except Exception as e:
            print(f"L·ªói kh·ªüi t·∫°o detector cho item {item_id}: {e}")
            # Fallback - th·ª≠ v·ªõi specific GPU
            current_process = multiprocessing.current_process()
            if hasattr(current_process, '_identity') and current_process._identity:
                fallback_gpu = str((current_process._identity[0] - 1) % NUM_GPU)
            else:
                fallback_gpu = '0'
            print(f"Th·ª≠ l·∫°i v·ªõi GPU {fallback_gpu}...")
            detector = create_detector(device=fallback_gpu)
        
        # L·∫•y danh s√°ch ·∫£nh c·∫ßn predict
        image_paths = get_image_paths_from_base(tiny_face_module, BASE_IMAGE_PATH)
        
        if not image_paths:
            print(f"Kh√¥ng t√¨m th·∫•y ·∫£nh cho item_id {item_id} t·∫°i {tiny_face_module}")
            return None
        
        all_frames_data = []
        total_start_time = time.time()
        max_faces_count = 0
        max_faces_frame_data = None
        
        for frame_idx, img_path in enumerate(image_paths):
            try:
                # Detect faces
                faces_data, elapsed = detect_faces(detector, img_path)
                
                # Load image ƒë·ªÉ l∆∞u sau n√†y
                image = Image.open(img_path).convert("RGB")
                img_width, img_height = image.size
                
                # Chu·∫©n b·ªã d·ªØ li·ªáu cho frame n√†y
                bboxes_data = []
                confidence_data = []
                class_names_data = []
                class_indexes_data = []
                class_groups_data = []
                scale_used_data = []
                
                # ƒêi·ªÅn d·ªØ li·ªáu cho c√°c face th·ª±c t·∫ø
                for face_data in faces_data:
                    norm_bbox = normalize_bbox(face_data['bbox'], img_width, img_height)
                    if norm_bbox:
                        bboxes_data.append(norm_bbox)
                        confidence_data.append(face_data['conf'])
                        class_names_data.append("face")
                        class_indexes_data.append(0)
                        class_groups_data.append("face")
                        scale_used_data.append(face_data.get('scale_used', 'unknown'))
                
                frame_data = {
                    "frame_idx": frame_idx,
                    "image_path": img_path,
                    "num_faces": len(faces_data),
                    "bboxes": bboxes_data,
                    "confidence": confidence_data,
                    "class_names": class_names_data,
                    "class_indexes": class_indexes_data,
                    "class_groups": class_groups_data,
                    "scale_used": scale_used_data,
                    "infer_time": elapsed,
                    "faces_data": faces_data,  # L∆∞u faces ƒë·ªÉ v·∫Ω sau n√†y
                    "image": image   # L∆∞u ·∫£nh ƒë·ªÉ v·∫Ω sau n√†y
                }
                
                all_frames_data.append(frame_data)
                
                # Theo d√µi frame c√≥ nhi·ªÅu face nh·∫•t
                if len(faces_data) > max_faces_count:
                    max_faces_count = len(faces_data)
                    max_faces_frame_data = frame_data
                
            except Exception as e:
                print(f"L·ªói x·ª≠ l√Ω frame {frame_idx} c·ªßa item {item_id}: {e}")
                continue
        
        total_elapsed = time.time() - total_start_time
        
        if not all_frames_data:
            print(f"Kh√¥ng c√≥ frame n√†o ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng cho item_id {item_id}")
            return None
        
        # T·∫°o JSON theo format y√™u c·∫ßu cho t·∫•t c·∫£ frames
        num_frames = len(all_frames_data)
        max_faces_per_frame = max([frame["num_faces"] for frame in all_frames_data]) if all_frames_data else 0
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu theo shape [num_frames, max_faces, 4]
        all_bboxes = []
        all_confidence = []
        all_class_names = []
        all_class_indexes = []
        all_class_groups = []
        all_scales_used = []
        
        for frame_data in all_frames_data:
            # Pad frame data to max_faces_per_frame
            frame_bboxes = frame_data["bboxes"] + [[-1.0, -1.0, -1.0, -1.0]] * (max_faces_per_frame - frame_data["num_faces"])
            frame_confidence = frame_data["confidence"] + [-1.0] * (max_faces_per_frame - frame_data["num_faces"])
            frame_class_names = frame_data["class_names"] + ["unknown"] * (max_faces_per_frame - frame_data["num_faces"])
            frame_class_indexes = frame_data["class_indexes"] + [-1] * (max_faces_per_frame - frame_data["num_faces"])
            frame_class_groups = frame_data["class_groups"] + ["unknown"] * (max_faces_per_frame - frame_data["num_faces"])
            frame_scales = frame_data["scale_used"] + ["unknown"] * (max_faces_per_frame - frame_data["num_faces"])
            
            all_bboxes.append(frame_bboxes)
            all_confidence.append(frame_confidence)
            all_class_names.append(frame_class_names)
            all_class_indexes.append(frame_class_indexes)
            all_class_groups.append(frame_class_groups)
            all_scales_used.append(frame_scales)
        
        json_data = {
            "yolo_face_prediction": [
                {
                    "name": "yolo-face-bboxes",
                    "datatype": "FP32",
                    "shape": [num_frames, max_faces_per_frame, 4],
                    "data": all_bboxes
                },
                {
                    "name": "yolo-face-confidence",
                    "datatype": "FP32",
                    "shape": [num_frames, max_faces_per_frame],
                    "data": all_confidence
                },
                {
                    "name": "yolo-face-class_names",
                    "datatype": "BYTES",
                    "shape": [num_frames, max_faces_per_frame],
                    "data": all_class_names
                },
                {
                    "name": "yolo-face-class_indexes",
                    "datatype": "INT32",
                    "shape": [num_frames, max_faces_per_frame],
                    "data": all_class_indexes
                },
                {
                    "name": "yolo-face-class_groups",
                    "datatype": "BYTES",
                    "shape": [num_frames, max_faces_per_frame],
                    "data": all_class_groups
                },
                {
                    "name": "yolo-face-scale_used",
                    "datatype": "BYTES",
                    "shape": [num_frames, max_faces_per_frame],
                    "data": all_scales_used
                },
                {
                    "name": "yolo-face-ckpt_version",
                    "datatype": "BYTES",
                    "shape": [num_frames],
                    "data": ["yolo_w6_face_multiscale_v1"] * num_frames
                },
                {
                    "name": "yolo-face-infer_time",
                    "datatype": "FP32",
                    "shape": [num_frames],
                    "data": [frame_data["infer_time"] for frame_data in all_frames_data]
                },
                {
                    "name": "yolo-face-total_time",
                    "datatype": "FP32",
                    "shape": [1],
                    "data": [total_elapsed]
                }
            ]
        }
        
        # L∆∞u JSON
        json_path = os.path.join(JSON_OUTPUT_DIR, f"{item_id}.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        # L∆∞u ·∫£nh c√≥ nhi·ªÅu face nh·∫•t v·ªõi bounding box
        if max_faces_frame_data and max_faces_count > 0:
            try:
                # T·∫°o copy c·ªßa ·∫£nh ƒë·ªÉ v·∫Ω
                image_with_boxes = max_faces_frame_data["image"].copy()
                image_with_boxes = draw_faces_on_image(image_with_boxes, max_faces_frame_data["faces_data"])
                
                # L∆∞u ·∫£nh
                max_faces_image_path = os.path.join(MAX_FACES_IMAGES_DIR, f"{item_id}_max_{max_faces_count}_faces.jpg")
                image_with_boxes.save(max_faces_image_path, "JPEG", quality=95)
                print(f"Saved max faces image: {max_faces_image_path}")
            except Exception as e:
                print(f"L·ªói l∆∞u ·∫£nh max faces cho item {item_id}: {e}")
        
        total_faces = sum([frame["num_faces"] for frame in all_frames_data])
        print(f"Item {item_id}: {num_frames} frames, {total_faces} total faces, max {max_faces_count} faces/frame -> {json_path}")
        
        return (item_id, num_frames, total_faces, total_elapsed)
        
    except Exception as e:
        print(f"L·ªói x·ª≠ l√Ω item_id {item_id}: {e}")
        return None


def create_new_directories(base_json_dir, base_images_dir):
    """
    T·∫°o th∆∞ m·ª•c m·ªõi v·ªõi t√™n c√≥ th√™m 'new' ·ªü cu·ªëi
    
    Args:
        base_json_dir: Th∆∞ m·ª•c JSON g·ªëc
        base_images_dir: Th∆∞ m·ª•c ·∫£nh g·ªëc
        
    Returns:
        new_json_dir, new_images_dir: ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c m·ªõi
    """
    # T·∫°o t√™n th∆∞ m·ª•c m·ªõi
    new_json_dir = base_json_dir.rstrip('/') + '_new'
    new_images_dir = base_images_dir.rstrip('/') + '_new'
    
    # N·∫øu th∆∞ m·ª•c _new ƒë√£ t·ªìn t·∫°i, th√™m s·ªë v√†o cu·ªëi
    counter = 1
    original_json = new_json_dir
    original_images = new_images_dir
    
    while os.path.exists(new_json_dir) or os.path.exists(new_images_dir):
        new_json_dir = f"{original_json}_{counter}"
        new_images_dir = f"{original_images}_{counter}"
        counter += 1
    
    # T·∫°o th∆∞ m·ª•c
    os.makedirs(new_json_dir, exist_ok=True)
    os.makedirs(new_images_dir, exist_ok=True)
    
    print(f"‚úÖ ƒê√£ t·∫°o th∆∞ m·ª•c m·ªõi:")
    print(f"   JSON: {new_json_dir}")
    print(f"   Images: {new_images_dir}")
    
    return new_json_dir, new_images_dir


def check_current_progress(json_dir, images_dir, items_data):
    """
    Ki·ªÉm tra ti·∫øn ƒë·ªô hi·ªán t·∫°i v√† h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën ti·∫øp t·ª•c kh√¥ng
    
    Args:
        json_dir: Th∆∞ m·ª•c ch·ª©a JSON
        images_dir: Th∆∞ m·ª•c ch·ª©a ·∫£nh
        items_data: Danh s√°ch c√°c items c·∫ßn x·ª≠ l√Ω
        
    Returns:
        should_continue: True n·∫øu ti·∫øp t·ª•c, False n·∫øu b·∫Øt ƒë·∫ßu l·∫°i
        updated_json_dir: Th∆∞ m·ª•c JSON (c√≥ th·ªÉ l√† m·ªõi)
        updated_images_dir: Th∆∞ m·ª•c ·∫£nh (c√≥ th·ªÉ l√† m·ªõi)
    """
    if not os.path.exists(json_dir) and not os.path.exists(images_dir):
        print("üìÇ Th∆∞ m·ª•c output ch∆∞a t·ªìn t·∫°i, s·∫Ω t·∫°o m·ªõi...")
        return True, json_dir, images_dir
    
    # ƒê·∫øm s·ªë items ƒë√£ x·ª≠ l√Ω th√†nh c√¥ng
    processed_count = 0
    total_items = len(items_data)
    
    for item_id, _ in items_data:
        json_path = os.path.join(json_dir, f"{item_id}.json")
        max_faces_image_path = os.path.join(images_dir, f"{item_id}_max_*.jpg")
        max_faces_images = glob.glob(max_faces_image_path)
        
        if os.path.exists(json_path) and max_faces_images:
            processed_count += 1
    
    if processed_count == 0:
        print("üìä Ch∆∞a c√≥ items n√†o ƒë∆∞·ª£c x·ª≠ l√Ω trong th∆∞ m·ª•c hi·ªán t·∫°i.")
        return True, json_dir, images_dir
    
    # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô hi·ªán t·∫°i
    progress_percent = (processed_count / total_items) * 100
    remaining_items = total_items - processed_count
    
    print("\n" + "="*60)
    print("üìä KI·ªÇM TRA TI·∫æN ƒê·ªò HI·ªÜN T·∫†I")
    print("="*60)
    print(f"üìÅ Th∆∞ m·ª•c JSON: {json_dir}")
    print(f"üìÅ Th∆∞ m·ª•c Images: {images_dir}")
    print(f"‚úÖ ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng: {processed_count}/{total_items} items ({progress_percent:.1f}%)")
    print(f"‚è≥ C√≤n l·∫°i c·∫ßn x·ª≠ l√Ω: {remaining_items} items")
    
    if processed_count > 0:
        # Hi·ªÉn th·ªã m·ªôt s·ªë items ƒë√£ x·ª≠ l√Ω g·∫ßn ƒë√¢y
        processed_items = []
        for item_id, _ in items_data:
            json_path = os.path.join(json_dir, f"{item_id}.json")
            max_faces_image_path = os.path.join(images_dir, f"{item_id}_max_*.jpg")
            max_faces_images = glob.glob(max_faces_image_path)
            
            if os.path.exists(json_path) and max_faces_images:
                try:
                    # L·∫•y th·ªùi gian s·ª≠a ƒë·ªïi file
                    json_mtime = os.path.getmtime(json_path)
                    processed_items.append((item_id, json_mtime))
                except:
                    processed_items.append((item_id, 0))
        
        # S·∫Øp x·∫øp theo th·ªùi gian m·ªõi nh·∫•t
        processed_items.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nüìã 5 items ƒë∆∞·ª£c x·ª≠ l√Ω g·∫ßn ƒë√¢y nh·∫•t:")
        for i, (item_id, mtime) in enumerate(processed_items[:5]):
            if mtime > 0:
                time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(mtime))
                print(f"   {i+1}. {item_id} (l√∫c {time_str})")
            else:
                print(f"   {i+1}. {item_id}")
    
    print("="*60)
    
    # H·ªèi ng∆∞·ªùi d√πng
    while True:
        try:
            user_input = input("\n‚ùì B·∫°n mu·ªën ti·∫øp t·ª•c x·ª≠ l√Ω t·ª´ ch·ªó ƒë√£ d·ª´ng? (y/n): ").strip().lower()
            
            if user_input in ['y', 'yes']:
                print("‚úÖ S·∫Ω ti·∫øp t·ª•c x·ª≠ l√Ω c√°c items c√≤n l·∫°i...")
                return True, json_dir, images_dir
            
            elif user_input in ['n', 'no']:
                print("üîÑ S·∫Ω b·∫Øt ƒë·∫ßu l·∫°i v·ªõi th∆∞ m·ª•c m·ªõi...")
                new_json_dir, new_images_dir = create_new_directories(json_dir, images_dir)
                return False, new_json_dir, new_images_dir
            
            else:
                print("‚ùå Vui l√≤ng nh·∫≠p 'y' (c√≥) ho·∫∑c 'n' (kh√¥ng)")
                
        except KeyboardInterrupt:
            print("\n\nüëã Ch∆∞∆°ng tr√¨nh b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
            sys.exit(0)
        except EOFError:
            print("\n\nüëã Ch∆∞∆°ng tr√¨nh b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
            sys.exit(0)


def main():
    """
    H√†m main ƒë·ªÉ ch·∫°y ch∆∞∆°ng tr√¨nh
    """
    # Khai b√°o global variables
    global MODEL_PATH, JSON_OUTPUT_DIR, MAX_FACES_IMAGES_DIR, BASE_IMAGE_PATH
    global CONF_THRES, IOU_THRES, IMG_SIZES, NUM_GPU, MAX_ITEMS, SKIP_PROCESSED
    
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='YOLOv7 Face Multi-Scale Detection with DataFrame JSON Output')
    parser.add_argument('--model', type=str, default=MODEL_PATH, help='path to model weights file')
    parser.add_argument('--output-dir', type=str, default=JSON_OUTPUT_DIR, help='directory to save JSON results')
    parser.add_argument('--max-faces-dir', type=str, default=MAX_FACES_IMAGES_DIR, help='directory to save max faces images')
    parser.add_argument('--img-sizes', nargs='+', type=int, default=IMG_SIZES, help='list of image sizes for multi-scale detection')
    parser.add_argument('--conf-thres', type=float, default=CONF_THRES, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=IOU_THRES, help='IoU threshold for NMS')
    parser.add_argument('--max-items', type=int, default=MAX_ITEMS, help='maximum number of items to process')
    parser.add_argument('--num-gpus', type=int, default=NUM_GPU, help='number of GPUs to use')
    parser.add_argument('--base-path', type=str, default=BASE_IMAGE_PATH, help='base path for images')
    parser.add_argument('--csv-file', type=str, 
                       default="/home/dainguyenvan/.clearml/cache/storage_manager/datasets/ds_4da1a9d86df546be86fede62610f7b64/val_data.csv",
                       help='CSV file containing item_id and tiny_face_module')
    parser.add_argument('--skip-processed', action='store_true', 
                      help='B·ªè qua c√°c item ƒë√£ x·ª≠ l√Ω (c√≥ JSON trong th∆∞ m·ª•c output)')
    parser.add_argument('--force-continue', action='store_true',
                      help='T·ª± ƒë·ªông ti·∫øp t·ª•c m√† kh√¥ng h·ªèi ng∆∞·ªùi d√πng')
    parser.add_argument('--force-restart', action='store_true', 
                      help='T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu l·∫°i v·ªõi th∆∞ m·ª•c m·ªõi m√† kh√¥ng h·ªèi ng∆∞·ªùi d√πng')
    
    args = parser.parse_args()
    
    MODEL_PATH = args.model
    JSON_OUTPUT_DIR = args.output_dir
    MAX_FACES_IMAGES_DIR = args.max_faces_dir
    BASE_IMAGE_PATH = args.base_path
    CONF_THRES = args.conf_thres
    IOU_THRES = args.iou_thres
    IMG_SIZES = args.img_sizes
    NUM_GPU = args.num_gpus
    MAX_ITEMS = args.max_items
    SKIP_PROCESSED = args.skip_processed
    
    print("üöÄ YOLOv7 Face Multi-Scale Detection v·ªõi DataFrame JSON Output")
    print(f"‚öôÔ∏è Config:")
    print(f"  - Model: {MODEL_PATH}")
    print(f"  - Output JSON: {JSON_OUTPUT_DIR}")
    print(f"  - Max Faces Images: {MAX_FACES_IMAGES_DIR}")
    print(f"  - Image Sizes: {IMG_SIZES}")
    print(f"  - Confidence Threshold: {CONF_THRES}")
    print(f"  - IoU Threshold: {IOU_THRES}")
    print(f"  - Base Image Path: {BASE_IMAGE_PATH}")
    print(f"  - GPUs Available: {NUM_GPU} (0,1,2)")
    print(f"  - CUDA Visible Devices: Workers will set individual GPU assignment")
    print(f"  - Skip Processed: {SKIP_PROCESSED}")
    
    # Check GPU availability
    if torch.cuda.is_available():
        print(f"  - CUDA Available: ‚úÖ ({torch.cuda.device_count()} devices detected)")
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"    GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
    else:
        print(f"  - CUDA Available: ‚ùå")
        print(f"  - Warning: CUDA kh√¥ng kh·∫£ d·ª•ng, s·∫Ω s·ª≠ d·ª•ng CPU (r·∫•t ch·∫≠m!)")
    print()
    
    # Load DataFrame
    print(f"üìã Loading DataFrame from: {args.csv_file}")
    df = pd.read_csv(args.csv_file)
    
    # Check columns
    required_columns = ['item_id', 'tiny_face_module']
    for col in required_columns:
        if col not in df.columns:
            print(f"‚ùå Column '{col}' not found in CSV. Available columns: {df.columns.tolist()}")
            return
    
    # L·∫•y items ƒë·∫ßu ti√™n
    df_subset = df.head(MAX_ITEMS)
    print(f"S·∫Ω x·ª≠ l√Ω {len(df_subset)} items")
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho multiprocessing
    items_data = [(row['item_id'], row['tiny_face_module']) for _, row in df_subset.iterrows()]
    
    # Ki·ªÉm tra ti·∫øn ƒë·ªô hi·ªán t·∫°i v√† h·ªèi ng∆∞·ªùi d√πng (tr·ª´ khi c√≥ force flags)
    if args.force_continue:
        print("üîß Force continue mode - s·∫Ω ti·∫øp t·ª•c x·ª≠ l√Ω...")
        should_continue = True
        final_json_dir = JSON_OUTPUT_DIR
        final_images_dir = MAX_FACES_IMAGES_DIR
    elif args.force_restart:
        print("üîÑ Force restart mode - t·∫°o th∆∞ m·ª•c m·ªõi...")
        should_continue = False
        final_json_dir, final_images_dir = create_new_directories(JSON_OUTPUT_DIR, MAX_FACES_IMAGES_DIR)
    else:
        should_continue, final_json_dir, final_images_dir = check_current_progress(
            JSON_OUTPUT_DIR, MAX_FACES_IMAGES_DIR, items_data)
    
    # C·∫≠p nh·∫≠t th√¥ng tin th∆∞ m·ª•c
    JSON_OUTPUT_DIR = final_json_dir
    MAX_FACES_IMAGES_DIR = final_images_dir
    
    # T·∫°o output directories n·∫øu ch∆∞a t·ªìn t·∫°i
    os.makedirs(JSON_OUTPUT_DIR, exist_ok=True)
    os.makedirs(MAX_FACES_IMAGES_DIR, exist_ok=True)
    
    # N·∫øu b·∫Øt ƒë·∫ßu l·∫°i, t·∫Øt skip-processed
    if not should_continue:
        SKIP_PROCESSED = False
        print("üîÑ B·∫Øt ƒë·∫ßu l·∫°i - t·∫Øt ch·∫ø ƒë·ªô skip-processed")
    
    # Gi·ªõi h·∫°n s·ªë process d·ª±a tr√™n s·ªë GPU
    n_process = min(cpu_count(), NUM_GPU * 2)  # 2 processes per GPU for better utilization
    if n_process < 1:
        n_process = 1
    
    print(f"üîß Processing Config:")
    print(f"  - Total Processes: {n_process}")
    print(f"  - Processes per GPU: {n_process // NUM_GPU if NUM_GPU > 0 else n_process}")
    print(f"  - GPU Assignment: Round-robin across GPUs 0,1,2 (per process)")
    print(f"  - Multiprocessing Method: spawn (CUDA compatible)")
    print(f"  - GPU Control: Each worker sets its own CUDA_VISIBLE_DEVICES")
    print(f"B·∫Øt ƒë·∫ßu predict cho {len(items_data)} items...")
    print()
    
    # Show initial GPU status
    print("üìä Initial GPU Status:")
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=index,name,memory.used,memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            for line in result.stdout.strip().split('\n'):
                parts = line.split(', ')
                if len(parts) >= 4:
                    gpu_id, name, mem_used, mem_total = parts[:4]
                    print(f"    GPU {gpu_id}: {name} - {mem_used}MB/{mem_total}MB used")
        else:
            print("    nvidia-smi not available")
    except Exception as e:
        print(f"    Could not get GPU status: {e}")
    print()
    
    # Ch·∫°y multiprocessing v·ªõi spawn method v√† worker initialization
    with Pool(processes=n_process, initializer=init_worker) as pool:
        results = list(tqdm(pool.imap(process_item_helper, items_data), total=len(items_data), desc="Processing items"))
    
    # Show final GPU status
    print("\nüìä Final GPU Status:")
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=index,name,memory.used,memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            for line in result.stdout.strip().split('\n'):
                parts = line.split(', ')
                if len(parts) >= 4:
                    gpu_id, name, mem_used, mem_total = parts[:4]
                    print(f"    GPU {gpu_id}: {name} - {mem_used}MB/{mem_total}MB used")
        else:
            print("    nvidia-smi not available")
    except Exception as e:
        print(f"    Could not get GPU status: {e}")
    print()
    
    # Th·ªëng k√™ k·∫øt qu·∫£
    successful_items = 0
    total_frames = 0
    total_faces = 0
    total_time = 0
    
    for result in results:
        if result is not None:
            item_id, num_frames, num_faces, elapsed = result
            successful_items += 1
            total_frames += num_frames
            total_faces += num_faces
            total_time += elapsed
    
    print(f"\n=== K·∫æT QU·∫¢ ===")
    print(f"Items x·ª≠ l√Ω th√†nh c√¥ng: {successful_items}/{len(items_data)}")
    print(f"T·ª∑ l·ªá th√†nh c√¥ng: {successful_items/len(items_data)*100:.1f}%")
    print(f"T·ªïng s·ªë frames: {total_frames}")
    print(f"T·ªïng s·ªë faces ph√°t hi·ªán: {total_faces}")
    print(f"Th·ªùi gian x·ª≠ l√Ω trung b√¨nh/item: {total_time/successful_items:.3f}s" if successful_items > 0 else "N/A")
    print(f"File JSON l∆∞u t·∫°i: {JSON_OUTPUT_DIR}")
    print(f"File ·∫£nh max faces l∆∞u t·∫°i: {MAX_FACES_IMAGES_DIR}")
    
    print(f"\nüéâ ƒê√É HO√ÄN TH√ÄNH: {successful_items} items th√†nh c√¥ng!")
    if successful_items < len(items_data):
        failed_items = len(items_data) - successful_items
        print(f"‚ö†Ô∏è  {failed_items} items th·∫•t b·∫°i")
    
    print(f"üìä T·ªïng c·ªông ƒë√£ x·ª≠ l√Ω: {successful_items}/{len(items_data)} items")


if __name__ == "__main__":
    main()
"""
# X·ª≠ l√Ω t·ª´ m·∫∑c ƒë·ªãnh CSV v·ªõi model m·∫∑c ƒë·ªãnh
python yolov7_face_multi_scale_dataframe_predict.py

# Ch·ªâ ƒë·ªãnh model v√† CSV
python yolov7_face_multi_scale_dataframe_predict.py --model yolov7-w6-face.pt --csv-file your_data.csv

# Tu·ª≥ ch·ªânh output v√† thresholds
python yolov7_face_multi_scale_dataframe_predict.py --output-dir ./json_output --max-faces-dir ./max_faces --conf-thres 0.6 --iou-thres 0.3

# Thay ƒë·ªïi scales cho multi-scale detection
python yolov7_face_multi_scale_dataframe_predict.py --img-sizes 640 1280 1920 3840

# H·∫°n ch·∫ø s·ªë items x·ª≠ l√Ω'
python yolov7_face_multi_scale_dataframe_predict.py --max-items 100
# b·ªè qua item ƒë√£ x·ª≠ l√Ω v√† x·ª≠ l√Ω ti·∫øp :python yolov7_face_multi_scale_dataframe_predict.py --force-continue
# x·ª≠ l√Ω t·ª´ ƒë·∫ßu: python yolov7_face_multi_scale_dataframe_predict.py --force-restart
"""